import numpy as np
import pandas as pd
import pingouin as pg
import plotly.graph_objects as go
import streamlit as st
from PIL import Image
from statsmodels.stats.multicomp import pairwise_tukeyhsd

import common


st.set_page_config(page_title="äºŒè¦å› æ··åˆåˆ†æ•£åˆ†æ", layout="wide")

st.title("äºŒè¦å› æ··åˆåˆ†æ•£åˆ†æ")
common.display_header()
st.write("è¢«é¨“è€…å†…å› å­ï¼ˆå‰æ¸¬ãƒ»å¾Œæ¸¬ï¼‰ã¨ã€è¢«é¨“è€…é–“å› å­ï¼ˆï¼‘ã¤ã®ã¿ï¼‰ã‚’ç”¨ã„ãŸæ··åˆANOVAã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")

# åˆ†æã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆï¼‰
try:
    image = Image.open('images/anova_mixed.png')
    st.image(image)
except Exception as e:
    st.warning("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
uploaded_file = st.file_uploader("CSVã¾ãŸã¯Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=["csv", "xlsx"])
use_demo_data = st.checkbox('ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨')

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = None
if use_demo_data:
    try:
        df = pd.read_excel('datasets/2way_anova_demo_mix.xlsx', sheet_name=0)
        st.write(df.head())
    except FileNotFoundError:
        st.error("ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    if uploaded_file is not None:
        try:
            if uploaded_file.type == 'text/csv':
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            st.write(df.head())
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# på€¤ã®è§£é‡ˆç”¨é–¢æ•°
def interpret_p(p):
    if p < 0.01:
        return "æœ‰æ„ãªå·®ãŒèªã‚ã‚‰ã‚Œã‚‹", "**"
    elif p < 0.05:
        return "æœ‰æ„ãªå·®ãŒèªã‚ã‚‰ã‚Œã‚‹", "*"
    elif p < 0.1:
        return "æœ‰æ„ãªå·®ãŒèªã‚ã‚‰ã‚Œã‚‹å‚¾å‘ã«ã‚ã‚‹", "â€ "
    else:
        return "æœ‰æ„ãªå·®ã¯èªã‚ã‚‰ã‚Œãªã„", "n.s."

# ãƒ–ãƒ©ã‚±ãƒƒãƒˆãƒ»ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ ç”¨ã®é–¢æ•°
def create_bracket_annotation(x0, x1, y, text):
    return dict(
        xref='x',
        yref='y',
        x=(x0 + x1) / 2,
        y=y,
        text=text,
        showarrow=False,
        font=dict(color='black'),
        xanchor='center',
        yanchor='bottom'
    )

def create_bracket_shape(x0, x1, y_vline_bottom, bracket_y):
    return dict(
        type='path',
        path=f'M {x0},{y_vline_bottom} L {x0},{bracket_y} L {x1},{bracket_y} L {x1},{y_vline_bottom}',
        line=dict(color='black'),
        xref='x',
        yref='y'
    )

def assign_levels(comparisons, category_positions):
    # ã‚«ãƒ†ã‚´ãƒªã®ä½ç½®ã‚’å–å¾—
    cat_positions = category_positions
    
    # å„æ¯”è¼ƒã‚’ä½ç½®ã§ã‚½ãƒ¼ãƒˆï¼ˆå·¦ç«¯ã®ä½ç½®ã€æ¬¡ã«å¹…ï¼‰
    sorted_comparisons = []
    for comp in comparisons:
        pos1 = cat_positions.get(comp[0], -1)
        pos2 = cat_positions.get(comp[1], -1)
        if pos1 == -1 or pos2 == -1:
            continue  # ã‚«ãƒ†ã‚´ãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        left = min(pos1, pos2)
        right = max(pos1, pos2)
        sorted_comparisons.append((left, right, comp))
    
    # å¹…ã®ç‹­ã„é †ã«ã‚½ãƒ¼ãƒˆï¼ˆç‹­ã„ã‚‚ã®ã‚’ä¸‹ã®ãƒ¬ãƒ™ãƒ«ã«é…ç½®ï¼‰
    sorted_comparisons.sort(key=lambda x: x[1] - x[0], reverse=False)
    
    # ãƒ¬ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦
    levels = []
    comparison_levels = []
    
    for left, right, comp in sorted_comparisons:
        # åˆ©ç”¨å¯èƒ½ãªæœ€ã‚‚ä½ã„ãƒ¬ãƒ™ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹
        assigned_level = None
        for level_idx, level_ranges in enumerate(levels):
            # ã“ã®ãƒ¬ãƒ™ãƒ«ã§é‡ãªã‚ŠãŒãªã„ã‹ãƒã‚§ãƒƒã‚¯
            can_place = True
            margin = 0.5  # ãƒ–ãƒ©ã‚±ãƒƒãƒˆé–“ã®ãƒãƒ¼ã‚¸ãƒ³ï¼ˆè¦–è¦šçš„ãªåˆ†é›¢ã‚’ç¢ºä¿ï¼‰
            for existing_left, existing_right in level_ranges:
                # ãƒ–ãƒ©ã‚±ãƒƒãƒˆãŒé‡ãªã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆãƒãƒ¼ã‚¸ãƒ³ã‚’è€ƒæ…®ï¼‰
                if not (right + margin <= existing_left or left - margin >= existing_right):
                    can_place = False
                    break
            
            if can_place:
                level_ranges.append((left, right))
                assigned_level = level_idx
                break
        
        # æ–°ã—ã„ãƒ¬ãƒ™ãƒ«ãŒå¿…è¦ãªå ´åˆ
        if assigned_level is None:
            levels.append([(left, right)])
            assigned_level = len(levels) - 1
        
        comparison_levels.append((comp, assigned_level))
    
    # å…ƒã®é †åºã«æˆ»ã™
    result_levels = []
    for comp in comparisons:
        for c, level in comparison_levels:
            if c == comp:
                result_levels.append(level)
                break
    
    return result_levels, len(levels)

if df is not None:
    st.subheader("ã€å¤‰æ•°ã®é¸æŠã€‘")
    all_cols = df.columns.tolist()
    
    # è¢«é¨“è€…IDã®é¸æŠï¼ˆå¿…é ˆï¼‰
    subject_col = st.selectbox("è¢«é¨“è€…IDã®åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ (å¿…é ˆ)", all_cols, index=0)
    
    # è¢«é¨“è€…é–“å› å­ã¯å€™è£œä¸€è¦§ã‹ã‚‰ï¼‘ã¤å¿…ãšé¸æŠ
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    if not categorical_cols:
        st.error("è¢«é¨“è€…é–“å› å­ã¨ã—ã¦åˆ©ç”¨ã§ãã‚‹ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
    else:
        selected_between = st.selectbox("è¢«é¨“è€…é–“å› å­ï¼ˆå¯¾å¿œãªã—ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆï¼‘ã¤ã®ã¿é¸æŠï¼‰", categorical_cols)
    
    # è¢«é¨“è€…å†…å› å­ï¼ˆå¯¾å¿œã‚ã‚Šï¼‰ã®é¸æŠï¼šè¦³æ¸¬å¤‰æ•°ï¼ˆå‰æ¸¬ï¼‰ã¨æ¸¬å®šå¤‰æ•°ï¼ˆå¾Œæ¸¬ï¼‰ã®ãƒšã‚¢ã‚’é¸æŠ
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    st.subheader("è¢«é¨“è€…å†…å› å­ã®é¸æŠ")
    st.write("ã€è¦³æ¸¬å¤‰æ•°ã€‘ï¼ˆå‰æ¸¬ï¼‰ã¨ã€æ¸¬å®šå¤‰æ•°ã€‘ï¼ˆå¾Œæ¸¬ï¼‰ã®ãƒšã‚¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    pre_vars = st.multiselect("è¦³æ¸¬å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„", numerical_cols, key="pre_vars")
    remaining_cols = [col for col in numerical_cols if col not in pre_vars]
    post_vars = st.multiselect("æ¸¬å®šå¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„", remaining_cols, key="post_vars")
    
    if len(pre_vars) != len(post_vars):
        st.error("è¦³æ¸¬å¤‰æ•°ã¨æ¸¬å®šå¤‰æ•°ã®æ•°ã¯åŒã˜ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚")
    elif not pre_vars or not post_vars:
        st.error("è¦³æ¸¬å¤‰æ•°ã¨æ¸¬å®šå¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success("åˆ†æå¯èƒ½ãªå¤‰æ•°ãŒé¸æŠã•ã‚Œã¾ã—ãŸã€‚")
        st.subheader("åˆ†æå‰ã®ç¢ºèª")
        for pre, post in zip(pre_vars, post_vars):
            st.write(f"â— {pre} â†’ {post}")
        st.write("ã“ã‚Œã‚‰ã®å¤‰æ•°ã«å‰å¾Œã®å·®ãŒã‚ã‚‹ã‹æ¤œå®šã—ã¾ã™ã€‚")
        
        final_tables = []
        
        # å„å¤‰æ•°ãƒšã‚¢ã”ã¨ã«å‡¦ç†
        for i, (pre, post) in enumerate(zip(pre_vars, post_vars)):
            st.markdown(f"## åˆ†æå¯¾è±¡å¤‰æ•°ãƒšã‚¢ {i+1}: {pre}ï¼ˆå‰æ¸¬ï¼‰ ã¨ {post}ï¼ˆå¾Œæ¸¬ï¼‰")
            
            # ãƒ¯ã‚¤ãƒ‰â†’ãƒ­ãƒ³ã‚°å¤‰æ›
            n = len(df)
            df_long = pd.DataFrame()
            df_long[subject_col] = np.repeat(df[subject_col].values, 2)
            df_long[selected_between] = np.repeat(df[selected_between].values, 2)
            df_long["Time"] = ["å‰", "å¾Œ"] * n
            df_long["value"] = np.concatenate([df[pre].values, df[post].values])
            
            st.write("ã€ã‚»ãƒ«ã”ã¨ã®è¦ç´„çµ±è¨ˆé‡ã€‘")
            desc = df_long.groupby([selected_between, "Time"])["value"].agg(["count", "mean", "std", "min", "max"]).reset_index()
            st.write(desc.style.format({"mean": "{:.2f}", "std": "{:.2f}", "min": "{:.2f}", "max": "{:.2f}"}))
            
            st.write("ã€æ··åˆANOVAã®å®Ÿè¡Œã€‘")
            try:
                aov = pg.mixed_anova(dv="value", within="Time", between=selected_between, subject=subject_col, data=df_long)
                st.write(aov)
            except Exception as e:
                st.error(f"æ··åˆANOVAå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                continue
            
            st.write("ã€å¤šé‡æ¯”è¼ƒï¼ˆTukey HSDãƒ†ã‚¹ãƒˆï¼‰ã€‘")
            df_long["Interaction"] = df_long[selected_between].astype(str) + "_" + df_long["Time"]
            try:
                tukey = pairwise_tukeyhsd(endog=df_long["value"], groups=df_long["Interaction"])
                tukey_df = pd.DataFrame(data=tukey._results_table.data[1:],
                                        columns=tukey._results_table.data[0])
                st.write(tukey_df)
            except Exception as e:
                st.error(f"Tukey HSDãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                continue
            
            st.subheader("ã€å¤šé‡æ¯”è¼ƒã®è§£é‡ˆã€‘")
            for idx, row in tukey_df.iterrows():
                group1 = row["group1"]
                group2 = row["group2"]
                p_val = row["p-adj"]
                interp_text, sig = interpret_p(p_val)
                st.write(f"ã€{group1} vs {group2}ã€‘ â†’ {interp_text} (p = {p_val:.3f} {sig})")
            
            st.subheader("ã€å¯è¦–åŒ–ã€‘")
            # å‰æ¸¬ãƒ»å¾Œæ¸¬ã‚’ã¾ã¨ã‚ãŸã‚°ãƒ©ãƒ•
            df_group = df_long.groupby([selected_between, "Time"]).agg(
                count=("value", "count"),
                mean=("value", "mean"),
                std=("value", "std")
            ).reset_index()
            df_group["se"] = df_group["std"] / np.sqrt(df_group["count"])
            levels = sorted(df_group[selected_between].unique())
            delta = 0.2
            category_positions = {grp: i for i, grp in enumerate(levels)}
            x_values = [category_positions[grp] for grp in levels]
            # å‰æ¸¬ã¯å·¦ã«ãšã‚‰ã—ã€å¾Œæ¸¬ã¯å³ã«ãšã‚‰ã™
            x_pre = [x - delta for x in x_values]
            x_post = [x + delta for x in x_values]
            pre_stats = df_group[df_group["Time"]=="å‰"].set_index(selected_between)
            post_stats = df_group[df_group["Time"]=="å¾Œ"].set_index(selected_between)
            pre_means = [pre_stats.loc[grp, "mean"] if grp in pre_stats.index else 0 for grp in levels]
            pre_err = [pre_stats.loc[grp, "se"] if grp in pre_stats.index else 0 for grp in levels]
            post_means = [post_stats.loc[grp, "mean"] if grp in post_stats.index else 0 for grp in levels]
            post_err = [post_stats.loc[grp, "se"] if grp in post_stats.index else 0 for grp in levels]
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=x_pre,
                y=pre_means,
                error_y=dict(type="data", array=pre_err, visible=True),
                name="å‰æ¸¬",
                marker_color="skyblue"
            ))
            fig.add_trace(go.Bar(
                x=x_post,
                y=post_means,
                error_y=dict(type="data", array=post_err, visible=True),
                name="å¾Œæ¸¬",
                marker_color="lightgreen"
            ))
            fig.update_xaxes(
                tickvals=x_values,
                ticktext=levels
            )
            
            # å„æ¡ä»¶ã”ã¨ã« Tukey HSD ã‚’å®Ÿæ–½ã—ã¦ã€ãƒ–ãƒ©ã‚±ãƒƒãƒˆã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼ˆå‰æ¸¬ï¼‰
            try:
                tukey_pre = pairwise_tukeyhsd(endog=df_long[df_long["Time"]=="å‰"]["value"],
                                              groups=df_long[df_long["Time"]=="å‰"][selected_between])
                tukey_pre_df = pd.DataFrame(data=tukey_pre._results_table.data[1:],
                                            columns=tukey_pre._results_table.data[0])
            except Exception as e:
                st.error(f"Tukey HSDãƒ†ã‚¹ãƒˆï¼ˆå‰æ¸¬ï¼‰å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                tukey_pre_df = pd.DataFrame()
            significant_comparisons_pre = []
            for _, row in tukey_pre_df.iterrows():
                grp1 = row['group1']
                grp2 = row['group2']
                p_value = row['p-adj']
                if p_value < 0.1:
                    if p_value < 0.01:
                        significance = '**'
                    elif p_value < 0.05:
                        significance = '*'
                    else:
                        significance = 'â€ '
                    significant_comparisons_pre.append((grp1, grp2, p_value, significance))
            comp_levels_pre, num_levels_pre = assign_levels(significant_comparisons_pre, category_positions) if significant_comparisons_pre else ([], 0)
            
            # å¾Œæ¸¬ã®æ¯”è¼ƒ
            try:
                tukey_post = pairwise_tukeyhsd(endog=df_long[df_long["Time"]=="å¾Œ"]["value"],
                                               groups=df_long[df_long["Time"]=="å¾Œ"][selected_between])
                tukey_post_df = pd.DataFrame(data=tukey_post._results_table.data[1:],
                                             columns=tukey_post._results_table.data[0])
            except Exception as e:
                st.error(f"Tukey HSDãƒ†ã‚¹ãƒˆï¼ˆå¾Œæ¸¬ï¼‰å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                tukey_post_df = pd.DataFrame()
            significant_comparisons_post = []
            for _, row in tukey_post_df.iterrows():
                grp1 = row['group1']
                grp2 = row['group2']
                p_value = row['p-adj']
                if p_value < 0.1:
                    if p_value < 0.01:
                        significance = '**'
                    elif p_value < 0.05:
                        significance = '*'
                    else:
                        significance = 'â€ '
                    significant_comparisons_post.append((grp1, grp2, p_value, significance))
            comp_levels_post, num_levels_post = assign_levels(significant_comparisons_post, category_positions) if significant_comparisons_post else ([], 0)
            
            base_y_max = max(max(np.array(pre_means) + np.array(pre_err)),
                             max(np.array(post_means) + np.array(post_err))) * 1.1
            num_groups = len(levels)

            # ã‚ªãƒ•ã‚»ãƒƒãƒˆã¨ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºã‚’ç¾¤æ•°ã¨ãƒ¬ãƒ™ãƒ«æ•°ã«å¿œã˜ã¦èª¿æ•´
            y_offset = base_y_max * max(0.06, 0.15 / num_groups)  # ç¾¤ãŒå¤šã„ã»ã©ç›¸å¯¾çš„ã«å°ã•ã
            step_size = base_y_max * max(0.10, 0.25 / num_groups)  # ç¾¤ãŒå¤šã„ã»ã©ç›¸å¯¾çš„ã«å°ã•ã

            # ãƒ¬ãƒ™ãƒ«æ•°ãŒå¤šã„å ´åˆã¯ã•ã‚‰ã«èª¿æ•´
            max_num_levels = max(num_levels_pre, num_levels_post)
            if max_num_levels > 3:
                step_size = step_size * (1 + (max_num_levels - 3) * 0.1)

            # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é…ç½®ã®èª¿æ•´ä¿‚æ•°ï¼ˆç¾¤æ•°ã«å¿œã˜ã¦å‹•çš„ã«èª¿æ•´ï¼‰
            vline_bottom_factor = max(0.3, 0.8 / num_groups)  # ãƒ–ãƒ©ã‚±ãƒƒãƒˆä¸‹ç«¯ã®ä½™ç™½
            bracket_offset_factor = max(0.2, 0.5 / num_groups)  # ãƒ–ãƒ©ã‚±ãƒƒãƒˆä¸Šç«¯ã®è¿½åŠ ä½™ç™½
            annotation_offset_factor = max(0.3, 0.8 / num_groups)  # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½™ç™½

            # å‰æ¸¬ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆãƒ»ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
            for idx, (comp, level) in enumerate(zip(significant_comparisons_pre, comp_levels_pre)):
                grp1, grp2, p_value, significance = comp
                if grp1 in category_positions and grp2 in category_positions:
                    x0 = category_positions[grp1] - delta
                    x1 = category_positions[grp2] - delta
                    y_vline_bottom = max(pre_means[levels.index(grp1)] + pre_err[levels.index(grp1)],
                                         pre_means[levels.index(grp2)] + pre_err[levels.index(grp2)]) + y_offset * vline_bottom_factor
                    bracket_y = y_vline_bottom + (level * step_size) + y_offset * bracket_offset_factor
                    fig.add_shape(create_bracket_shape(x0, x1, y_vline_bottom, bracket_y))
                    annotation_y = bracket_y + y_offset * annotation_offset_factor
                    fig.add_annotation(create_bracket_annotation(x0, x1, annotation_y, f'p < {p_value:.2f} {significance}'))

            # å¾Œæ¸¬ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆãƒ»ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
            for idx, (comp, level) in enumerate(zip(significant_comparisons_post, comp_levels_post)):
                grp1, grp2, p_value, significance = comp
                if grp1 in category_positions and grp2 in category_positions:
                    x0 = category_positions[grp1] + delta
                    x1 = category_positions[grp2] + delta
                    y_vline_bottom = max(post_means[levels.index(grp1)] + post_err[levels.index(grp1)],
                                         post_means[levels.index(grp2)] + post_err[levels.index(grp2)]) + y_offset * vline_bottom_factor
                    bracket_y = y_vline_bottom + (level * step_size) + y_offset * bracket_offset_factor
                    fig.add_shape(create_bracket_shape(x0, x1, y_vline_bottom, bracket_y))
                    annotation_y = bracket_y + y_offset * annotation_offset_factor
                    fig.add_annotation(create_bracket_annotation(x0, x1, annotation_y, f'p < {p_value:.2f} {significance}'))
            
            fig.update_yaxes(range=[0, base_y_max + (max_num_levels * step_size) + y_offset * 2.5])
            fig.update_layout(font=dict(family="IPAexGothic"), barmode="group", title_text=f"{pre}ãƒ»{post} ã® å‰å¾Œã¾ã¨ã‚ãŸçµæœ")
            st.plotly_chart(fig, use_container_width=True)

            # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯
            excel_data = common.export_plotly_to_excel(fig, filename=f"äºŒè¦å› æ··åˆåˆ†æ•£åˆ†æ_{pre}_{post}.xlsx", sheet_name="ã‚°ãƒ©ãƒ•")
            import base64
            b64 = base64.b64encode(excel_data).decode()
            href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="äºŒè¦å› æ··åˆåˆ†æ•£åˆ†æ_{pre}_{post}.xlsx">ğŸ“Š ã‚°ãƒ©ãƒ•ã‚’Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
            st.markdown(href, unsafe_allow_html=True)

            # å„ç¾¤ã®å¹³å‡å€¤ (SD) ã‚’è¨ˆç®—ï¼ˆå…¨ã¦ã®æ™‚é–“ç‚¹ã®å€¤ã®å¹³å‡ã‚’ä½¿ç”¨ï¼‰
            group_summary = df_long.groupby(selected_between)["value"].agg(['mean', 'std', 'count']).reset_index()
            group_summary['se'] = group_summary['std'] / np.sqrt(group_summary['count'])
            group_means = dict(zip(group_summary[selected_between], group_summary['mean']))
            group_errors = dict(zip(group_summary[selected_between], group_summary['se']))
            caption_text = "å„ç¾¤ã®å¹³å‡å€¤ (SE): " + ", ".join([
                f"{grp}: {group_means[grp]:.2f} ({group_errors[grp]:.2f})" for grp in sorted(levels)
            ])
            st.caption(caption_text)
            
            # â‘¥ å„å¾“å±å¤‰æ•°ã®å…¨ä½“çµæœã®ã¾ã¨ã‚ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆï¼ˆãƒ”ãƒœãƒƒãƒˆå½¢å¼ï¼‰
            summary = df_long.groupby([selected_between, "Time"]).agg(
                mean=("value", "mean"),
                std=("value", "std")
            ).reset_index()
            pivot_df = summary.pivot(index=selected_between, columns="Time", values=["mean", "std"])
            pivot_df.columns = [f"{col[1]}_{'M' if col[0]=='mean' else 'S.D'}" for col in pivot_df.columns]
            pivot_df = pivot_df.reset_index()
            pivot_df.insert(0, "å¤‰æ•°", pre)
            # ANOVAçµæœã‹ã‚‰åŠ¹æœã®è¨˜å·ã‚’æŠ½å‡ºï¼ˆå­˜åœ¨ã—ãªã‘ã‚Œã° "n.s."ï¼‰
            if not aov[aov["Source"]=="Between"].empty:
                p_between_val = aov.loc[aov["Source"]=="Between", "p-unc"].values[0]
                _, sig_between = interpret_p(p_between_val)
            else:
                sig_between = "n.s."
            if not aov[aov["Source"]=="Time"].empty:
                p_time_val = aov.loc[aov["Source"]=="Time", "p-unc"].values[0]
                _, sig_time = interpret_p(p_time_val)
            else:
                sig_time = "n.s."
            if not aov[aov["Source"]=="Interaction"].empty:
                p_interaction_val = aov.loc[aov["Source"]=="Interaction", "p-unc"].values[0]
                _, sig_interaction = interpret_p(p_interaction_val)
            else:
                sig_interaction = "n.s."
            pivot_df[f"{selected_between}ã®ä¸»åŠ¹æœ"] = ""
            pivot_df["å‰å¾Œã®ä¸»åŠ¹æœ"] = ""
            pivot_df["äº¤äº’ä½œç”¨"] = ""
            pivot_df.loc[pivot_df.index[0], f"{selected_between}ã®ä¸»åŠ¹æœ"] = sig_between
            pivot_df.loc[pivot_df.index[0], "å‰å¾Œã®ä¸»åŠ¹æœ"] = sig_time
            pivot_df.loc[pivot_df.index[0], "äº¤äº’ä½œç”¨"] = sig_interaction
            # æ•°å€¤ã‚’å°æ•°ç‚¹ç¬¬2ä½ã¾ã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã«æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆä¾‹: 5.0 -> "5.00"ï¼‰
            pivot_df = pivot_df.applymap(lambda x: "{:.2f}".format(x) if isinstance(x, (int, float)) else x)
            final_tables.append(pivot_df)
        
        # å…¨å¾“å±å¤‰æ•°ã®ã¾ã¨ã‚ï¼ˆé€£çµã—ã¦è¡¨ç¤ºï¼‰
        if final_tables:
            st.subheader("ã€å…¨ä½“çµæœã®ã¾ã¨ã‚ã€‘")
            all_final = pd.concat(final_tables, ignore_index=True)
            st.dataframe(all_final)
            st.caption("p<0.1â€    p<0.05*   p<0.01**")
        
        common.display_copyright()
        common.display_special_thanks()
